{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788c9ce0",
   "metadata": {},
   "source": [
    "# PEP Prediction Model Training in Python\n",
    "\n",
    "This notebook trains Gradient Boosting Machine (GBM) models for PEP (Post-ERCP Pancreatitis) prediction, converting the original R-based models to Python.\n",
    "\n",
    "## Models trained:\n",
    "1. **Main GBM model** - trained on the full dataset\n",
    "2. **Therapy-specific GBM models** - trained on subsets for different treatments:\n",
    "   - Aggressive hydration only\n",
    "   - Indomethacin only\n",
    "   - Aggressive hydration and indomethacin\n",
    "   - PD stent only\n",
    "   - Indomethacin and PD stent\n",
    "\n",
    "The models use the same preprocessing and parameters as the original R implementation to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6793965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for R-exact implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimpy import skim\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653c094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded (dt): (7389, 29)\n",
      "29 Features: ['study_id', 'age_years', 'gender_male_1', 'bmi', 'sod', 'history_of_pep', 'hx_of_recurrent_pancreatitis', 'pancreatic_sphincterotomy', 'precut_sphincterotomy', 'minor_papilla_sphincterotomy', 'failed_cannulation', 'difficult_cannulation', 'pneumatic_dilation_of_intact_biliary_sphincter', 'pancreatic_duct_injection', 'pancreatic_duct_injections_2', 'acinarization', 'trainee_involvement', 'cholecystectomy', 'pancreo_biliary_malignancy', 'guidewire_cannulation', 'guidewire_passage_into_pancreatic_duct', 'guidewire_passage_into_pancreatic_duct_2', 'biliary_sphincterotomy', 'indomethacin_nsaid_prophylaxis', 'aggressive_hydration', 'pancreatic_duct_stent_placement', 'pep', 'patient_id', 'study_id']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'At this point, there are 29 features in R.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read RAW data before imputation\n",
    "dt_raw = pd.read_excel(\"/Users/emilyguan/Downloads/EndoScribe/pep_prediction/AlbertCodeFiles/data/Combined sheet final December.xlsx\")\n",
    "\n",
    "# Clean variable names\n",
    "dt = dt_raw.copy()\n",
    "dt.columns = dt.columns.str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "dt = dt.dropna(subset=['pep'])  # blank rows\n",
    "# Convert values with \".\" to None\n",
    "dt.replace('.', np.nan, inplace=True)\n",
    "\n",
    "# Add patient_id (matching R: mutate(patient_id = 1:n()))\n",
    "dt['patient_id'] = range(1, len(dt) + 1)\n",
    "\n",
    "# Convert data types\n",
    "dt['study_id'] = dt['study'].astype('category')\n",
    "dt['pep'] = dt['pep'].astype('category')\n",
    "dt['bmi'] = pd.to_numeric(dt['bmi'], errors='coerce')\n",
    "\n",
    "# Rename columns\n",
    "dt = dt.rename(columns={\n",
    "    'study': 'study_id',\n",
    "    'panc_inj>2': 'pancreatic_duct_injections_2',\n",
    "    'age': 'age_years',\n",
    "    'gender_': 'gender_male_1',\n",
    "    'recurr_panc': 'hx_of_recurrent_pancreatitis',\n",
    "    'panc_sphinc': 'pancreatic_sphincterotomy',\n",
    "    'precut_sphinc': 'precut_sphincterotomy',\n",
    "    'min_pap_sphinc': 'minor_papilla_sphincterotomy',\n",
    "    'failed_cann': 'failed_cannulation',\n",
    "    'diff_cann': 'difficult_cannulation',\n",
    "    'pneum_dil_wobs': 'pneumatic_dilation_of_intact_biliary_sphincter',\n",
    "    'panc_inj': 'pancreatic_duct_injection',\n",
    "    'acinarz': 'acinarization',\n",
    "    'panc_brush_cyto': 'pancreatic_duct_brush_cytology',\n",
    "    'panc_div': 'pancreas_divisum',\n",
    "    'trainee': 'trainee_involvement',\n",
    "    'cholecy': 'cholecystectomy',\n",
    "    'pb_mal': 'pancreo_biliary_malignancy',\n",
    "    'gw_cann': 'guidewire_cannulation',\n",
    "    'gw_passpd': 'guidewire_passage_into_pancreatic_duct',\n",
    "    '>2gw_passpd': 'guidewire_passage_into_pancreatic_duct_2',\n",
    "    'bil_sphinc': 'biliary_sphincterotomy',\n",
    "    'intensive_hydration': 'aggressive_hydration',\n",
    "    'nsaid_use': 'indomethacin_nsaid_prophylaxis',\n",
    "    'pd_stent': 'pancreatic_duct_stent_placement'\n",
    "})\n",
    "\n",
    "# \"Dummy variables\" and \"Near zero variance features\" sections in Rmd\n",
    "# early on, they remove pep_severity\n",
    "# \"due to high missingness and redundancy with `sod`, I will remove `type_of_sod`.\"\n",
    "# \"For now, I've chosen to remove the `pancreatic_duct_brush_cytology` and `pancreas_divisum` features\n",
    "\n",
    "dt = dt.drop(columns=['pep_severity', 'type_of_sod', 'pancreatic_duct_brush_cytology', 'pancreas_divisum'])\n",
    "\n",
    "print(f\"Raw data loaded (dt): {dt.shape}\")\n",
    "print(f\"{len(dt.columns.tolist())} Features: {dt.columns.tolist()}\")\n",
    "dt.head()\n",
    "\n",
    "\"\"\"At this point, there are 29 features in R.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9fed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Features: ['study_id', 'age_years', 'gender_male_1', 'bmi', 'sod', 'history_of_pep', 'hx_of_recurrent_pancreatitis', 'pancreatic_sphincterotomy', 'precut_sphincterotomy', 'minor_papilla_sphincterotomy', 'failed_cannulation', 'difficult_cannulation', 'pneumatic_dilation_of_intact_biliary_sphincter', 'pancreatic_duct_injection', 'pancreatic_duct_injections_2', 'acinarization', 'trainee_involvement', 'cholecystectomy', 'pancreo_biliary_malignancy', 'guidewire_cannulation', 'guidewire_passage_into_pancreatic_duct', 'guidewire_passage_into_pancreatic_duct_2', 'biliary_sphincterotomy', 'indomethacin_nsaid_prophylaxis', 'aggressive_hydration', 'pancreatic_duct_stent_placement', 'pep', 'patient_id', 'study_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>age_years</th>\n",
       "      <th>gender_male_1</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sod</th>\n",
       "      <th>history_of_pep</th>\n",
       "      <th>hx_of_recurrent_pancreatitis</th>\n",
       "      <th>pancreatic_sphincterotomy</th>\n",
       "      <th>precut_sphincterotomy</th>\n",
       "      <th>minor_papilla_sphincterotomy</th>\n",
       "      <th>...</th>\n",
       "      <th>guidewire_cannulation</th>\n",
       "      <th>guidewire_passage_into_pancreatic_duct</th>\n",
       "      <th>guidewire_passage_into_pancreatic_duct_2</th>\n",
       "      <th>biliary_sphincterotomy</th>\n",
       "      <th>indomethacin_nsaid_prophylaxis</th>\n",
       "      <th>aggressive_hydration</th>\n",
       "      <th>pancreatic_duct_stent_placement</th>\n",
       "      <th>pep</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  age_years  gender_male_1  bmi  sod  history_of_pep  \\\n",
       "0         1       26.0              0  NaN    1               0   \n",
       "1         1       29.0              0  NaN    1               0   \n",
       "2         1       19.0              1  NaN    0               0   \n",
       "3         1       38.0              0  NaN    0               0   \n",
       "4         1       63.0              1  NaN    0               0   \n",
       "\n",
       "   hx_of_recurrent_pancreatitis  pancreatic_sphincterotomy  \\\n",
       "0                           1.0                          0   \n",
       "1                           0.0                          0   \n",
       "2                           1.0                          1   \n",
       "3                           0.0                          1   \n",
       "4                           0.0                          0   \n",
       "\n",
       "   precut_sphincterotomy minor_papilla_sphincterotomy  ...  \\\n",
       "0                      0                          NaN  ...   \n",
       "1                      0                          NaN  ...   \n",
       "2                      0                          NaN  ...   \n",
       "3                      0                          NaN  ...   \n",
       "4                      0                          NaN  ...   \n",
       "\n",
       "   guidewire_cannulation  guidewire_passage_into_pancreatic_duct  \\\n",
       "0                    NaN                                     NaN   \n",
       "1                    NaN                                     NaN   \n",
       "2                    NaN                                     NaN   \n",
       "3                    NaN                                     NaN   \n",
       "4                    NaN                                     NaN   \n",
       "\n",
       "   guidewire_passage_into_pancreatic_duct_2 biliary_sphincterotomy  \\\n",
       "0                                       NaN                      0   \n",
       "1                                       NaN                      1   \n",
       "2                                       NaN                      0   \n",
       "3                                       NaN                      0   \n",
       "4                                       NaN                      1   \n",
       "\n",
       "   indomethacin_nsaid_prophylaxis  aggressive_hydration  \\\n",
       "0                             1.0                     0   \n",
       "1                             0.0                     0   \n",
       "2                             0.0                     0   \n",
       "3                             0.0                     0   \n",
       "4                             1.0                     0   \n",
       "\n",
       "   pancreatic_duct_stent_placement  pep  patient_id  study_id  \n",
       "0                                0    1           1         1  \n",
       "1                                1    1           2         1  \n",
       "2                                1    1           3         1  \n",
       "3                                1    1           4         1  \n",
       "4                                1    1           5         1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix specific missing/typo logic\n",
    "dt['aggressive_hydration'] = dt['aggressive_hydration'].fillna(0) # already no missing values\n",
    "dt['pancreatic_duct_stent_placement'] = dt['pancreatic_duct_stent_placement'].fillna(0) # already no missing values\n",
    "\n",
    "# If guidewire_passage_into_pancreatic_duct_2 == 1, then guidewire_passage_into_pancreatic_duct should also be 1\n",
    "dt.loc[dt['guidewire_passage_into_pancreatic_duct_2'] == 1, 'guidewire_passage_into_pancreatic_duct'] = 1\n",
    "# If guidewire_passage_into_pancreatic_duct == 0, then guidewire_passage_into_pancreatic_duct_2 should also be 0  \n",
    "dt.loc[dt['guidewire_passage_into_pancreatic_duct'] == 0, 'guidewire_passage_into_pancreatic_duct_2'] = 0\n",
    "\n",
    "# typo: 8 should be 1\n",
    "dt.loc[dt['pancreatic_duct_injections_2'] == 8, 'pancreatic_duct_injections_2'] = 1\n",
    "\n",
    "# If panc_inj>2 == 1, then pancreatic_duct_injection should also be 1\n",
    "dt.loc[dt['pancreatic_duct_injections_2'] == 1, 'pancreatic_duct_injection'] = 1\n",
    "# If pancreatic_duct_injection == 0, then panc_inj>2 should also be 0\n",
    "dt.loc[dt['pancreatic_duct_injection'] == 0, 'pancreatic_duct_injections_2'] = 0\n",
    "print(f\"{len(dt.columns.tolist())} Features: {dt.columns.tolist()}\")\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a5f25",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "From R: \n",
    "I use the `preProcess` function from `caret` to impute values. I either use median imputation (`medianImpute`) or k-nearest neighbors (`knnImpute`), with preference given to the latter whenever possible.\n",
    "\n",
    "Impute values for the samples/studies that are missing very few features first using `medianImpute` or some background knowledge. Then I use those samples to impute all the other samples using `knnImpute`.\n",
    "\n",
    "1. Set missing `guidewire_passage_into_pancreatic_duct` to 0 in study 12. Set missing `pancreatic_duct_injections_2` to 0 in study 5. Since these features are binary, this is equivalent to `medianImpute`.\n",
    "2. Use studies **12** and **5** to impute the rest of the studies with `knnImpute`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525da222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data types - convert mixed object columns to numeric\n",
    "def clean_numeric_column(df, col):\n",
    "    if col in df.columns:\n",
    "        # Replace spaces and other non-numeric strings with NaN\n",
    "        df[col] = df[col].replace(r'^\\s*$', np.nan, regex=True)  # Replace spaces/empty with NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, invalid -> NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e778e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(train, test, new_dataset=False):\n",
    "    print(f\"Starting imputation with train shape: {train.shape}, test shape: {test.shape}\")\n",
    "    train_impute_step1 = train.copy()\n",
    "\n",
    "    # Apply study-specific rules to training data\n",
    "    if 'guidewire_passage_into_pancreatic_duct' in train_impute_step1.columns and 'study_id' in train_impute_step1.columns:\n",
    "        mask = train_impute_step1['guidewire_passage_into_pancreatic_duct'].isna() & (train_impute_step1['study_id'] == 12)\n",
    "        fixes = mask.sum()\n",
    "        train_impute_step1.loc[mask, 'guidewire_passage_into_pancreatic_duct'] = 0\n",
    "        print(f\"  Fixed {fixes} guidewire values in train for study 12\")\n",
    "        \n",
    "    if 'pancreatic_duct_injections_2' in train_impute_step1.columns and 'study_id' in train_impute_step1.columns:\n",
    "        mask = train_impute_step1['pancreatic_duct_injections_2'].isna() & (train_impute_step1['study_id'] == 5)\n",
    "        fixes = mask.sum()\n",
    "        train_impute_step1.loc[mask, 'pancreatic_duct_injections_2'] = 0\n",
    "        print(f\"  Fixed {fixes} pancreatic injection values in train for study 5\")\n",
    "    \n",
    "    if not new_dataset: # Apply same rules to test data\n",
    "        test_impute_step1 = test.copy()        \n",
    "        if 'guidewire_passage_into_pancreatic_duct' in test_impute_step1.columns and 'study_id' in test_impute_step1.columns:\n",
    "            mask = test_impute_step1['guidewire_passage_into_pancreatic_duct'].isna() & (test_impute_step1['study_id'] == 12)\n",
    "            fixes = mask.sum()\n",
    "            test_impute_step1.loc[mask, 'guidewire_passage_into_pancreatic_duct'] = 0\n",
    "            print(f\"  Fixed {fixes} guidewire values in test for study 12\")\n",
    "        if 'pancreatic_duct_injections_2' in test_impute_step1.columns and 'study_id' in test_impute_step1.columns:\n",
    "            mask = test_impute_step1['pancreatic_duct_injections_2'].isna() & (test_impute_step1['study_id'] == 5)\n",
    "            fixes = mask.sum()\n",
    "            test_impute_step1.loc[mask, 'pancreatic_duct_injections_2'] = 0\n",
    "            print(f\"  Fixed {fixes} pancreatic injection values in test for study 5\")\n",
    "    else:\n",
    "        test_impute_step1 = test.copy()  # No changes if new_dataset=True\n",
    "    \n",
    "    # Clean both datasets\n",
    "    mixed_cols = ['minor_papilla_sphincterotomy', 'pancreatic_duct_injection', 'guidewire_passage_into_pancreatic_duct', 'guidewire_passage_into_pancreatic_duct_2', 'biliary_sphincterotomy', 'pep_severity']\n",
    "    for col in mixed_cols:\n",
    "        clean_numeric_column(train_impute_step1, col)\n",
    "        clean_numeric_column(test_impute_step1, col)\n",
    "    print(f\"  Cleaned mixed data types\")\n",
    "    \n",
    "    # Step 2: Center and scale\n",
    "    exclude_cols = ['study_id', 'pep', 'patient_id']\n",
    "    feature_cols = [col for col in train_impute_step1.columns if col not in exclude_cols]\n",
    "    # Only scale numeric columns\n",
    "    numeric_cols = []\n",
    "    for col in feature_cols:\n",
    "        if pd.api.types.is_numeric_dtype(train_impute_step1[col]):\n",
    "            numeric_cols.append(col)\n",
    "    \n",
    "    print(f\"  Found {len(numeric_cols)} numeric columns for processing\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = train_impute_step1.copy()\n",
    "    test_scaled = test_impute_step1.copy()\n",
    "\n",
    "    train_scaled[numeric_cols] = scaler.fit_transform(train_scaled[numeric_cols])\n",
    "    test_scaled[numeric_cols] = scaler.transform(test_scaled[numeric_cols])\n",
    "    \n",
    "    # Step 3: KNN imputation with k=10 (R's preProcess knnImpute)\n",
    "    # Check for constant columns that will be dropped by KNNImputer\n",
    "    train_pre_impute = train_scaled[numeric_cols]\n",
    "    constant_cols = [col for col in numeric_cols if train_pre_impute[col].nunique() <= 1]\n",
    "    impute_cols = [col for col in numeric_cols if col not in constant_cols]\n",
    "    \n",
    "    if len(impute_cols) > 0:\n",
    "        imputer = KNNImputer(n_neighbors=10)\n",
    "        train_imputed = imputer.fit_transform(train_scaled[impute_cols])\n",
    "        test_imputed = imputer.transform(test_scaled[impute_cols])\n",
    "        \n",
    "        train_scaled.loc[:, impute_cols] = train_imputed\n",
    "        test_scaled.loc[:, impute_cols] = test_imputed\n",
    "        print(f\"  Imputation completed\")\n",
    "    else:\n",
    "        print(f\"  No columns to impute (all constant)\")\n",
    "    \n",
    "    # Remove study_id (like R)\n",
    "    train_final = train_scaled#.drop(columns=['study_id'])\n",
    "    if not new_dataset and 'study_id' in test_scaled.columns:\n",
    "        test_final = test_scaled.drop(columns=['study_id'])\n",
    "    else:\n",
    "        test_final = test_scaled  # Keep study_id for new datasets\n",
    "    \n",
    "    print(f\"  Final shapes: train {train_final.shape}, test {test_final.shape}\")\n",
    "    # Return output matching R structure\n",
    "    return {'train': train_final, 'test': test_final}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea790766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['study_id', 'age_years', 'gender_male_1', 'bmi', 'sod', 'history_of_pep', 'hx_of_recurrent_pancreatitis', 'pancreatic_sphincterotomy', 'precut_sphincterotomy', 'minor_papilla_sphincterotomy', 'failed_cannulation', 'difficult_cannulation', 'pneumatic_dilation_of_intact_biliary_sphincter', 'pancreatic_duct_injection', 'pancreatic_duct_injections_2', 'acinarization', 'trainee_involvement', 'cholecystectomy', 'pancreo_biliary_malignancy', 'guidewire_cannulation', 'guidewire_passage_into_pancreatic_duct', 'guidewire_passage_into_pancreatic_duct_2', 'biliary_sphincterotomy', 'indomethacin_nsaid_prophylaxis', 'aggressive_hydration', 'pancreatic_duct_stent_placement', 'pep', 'patient_id']\n",
      "Data prepared: (7389, 28)\n",
      "Fold split: Train=5911, Test=1478\n",
      "Some stats before imputation:\n",
      "\tTrain mean age: 56.34055517941774, Test mean age: 56.34055517941774\n",
      "\tTrain mean bmi: 24.878963560257308, Test mean bmi: 24.878963560257308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'note stats before imputation are similar but differ at 0.01 to 1.0 precision. diff from handling of missing values? or random split?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- Imputation TESTING ------\n",
    "# Clean data (remove duplicate columns)\n",
    "dt_clean = dt.loc[:, ~dt.columns.duplicated()].copy()\n",
    "print(\"columns:\", dt_clean.columns.tolist())\n",
    "# Add patient_id like R: dt = dt %>% mutate(patient_id = 1:n())\n",
    "dt_clean['patient_id'] = range(1, len(dt_clean) + 1)\n",
    "\n",
    "print(f\"Data prepared: {dt_clean.shape}\")\n",
    "\n",
    "# Create 5-fold split exactly like R: createFolds(dt$pep, k = 5, list = TRUE)\n",
    "SEED = 1\n",
    "np.random.seed(SEED)  # set.seed(1)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "fold_splits = list(skf.split(dt_clean.drop(['pep'], axis=1), dt_clean['pep']))\n",
    "\n",
    "# Get Fold1 exactly like R: test_index$Fold1\n",
    "train_idx, test_idx = fold_splits[0]\n",
    "\n",
    "# Create train/test exactly like R:\n",
    "train = dt_clean.iloc[train_idx].copy().reset_index(drop=True)\n",
    "test = dt_clean.iloc[test_idx].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Fold split: Train={len(train)}, Test={len(test)}\") \n",
    "# R: Train rows: 5910, Test rows: 1479 \n",
    "\n",
    "# print out some stats about the splits: mean age, bmi\n",
    "print(f\"Some stats before imputation:\\n\\tTrain mean age: {test['age_years'].mean()}, Test mean age: {test['age_years'].mean()}\")\n",
    "print(f\"\\tTrain mean bmi: {test['bmi'].mean()}, Test mean bmi: {test['bmi'].mean()}\")\n",
    "\"\"\"note stats before imputation are similar but differ at 0.01 to 1.0 precision. diff from handling of missing values? or random split?\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971d14a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying imputation to whole dataset to test stats:\n",
      "Starting imputation with train shape: (5911, 28), test shape: (1478, 28)\n",
      "  Fixed 0 guidewire values in train for study 12\n",
      "  Fixed 14 pancreatic injection values in train for study 5\n",
      "  Fixed 0 guidewire values in test for study 12\n",
      "  Fixed 2 pancreatic injection values in test for study 5\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (5911, 28), test (1478, 27)\n",
      "  Train: (5911, 28), missing: 0\n",
      "  Test: (1478, 27), missing: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span> <span style=\"font-style: italic\">       Categories        </span>                                │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓ ┏━━━━━━━━━━━━━━━━━━━━━━━┓                                │\n",
       "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Categorical Variables </span>┃                                │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩ ┡━━━━━━━━━━━━━━━━━━━━━━━┩                                │\n",
       "│ │ Number of rows    │ 5911   │ │ float64     │ 25    │ │ pep                   │                                │\n",
       "│ │ Number of columns │ 28     │ │ int64       │ 2     │ └───────────────────────┘                                │\n",
       "│ └───────────────────┴────────┘ │ category    │ 1     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column        </span>┃<span style=\"font-weight: bold\"> NA </span>┃<span style=\"font-weight: bold\"> NA % </span>┃<span style=\"font-weight: bold\"> mean       </span>┃<span style=\"font-weight: bold\"> sd     </span>┃<span style=\"font-weight: bold\"> p0      </span>┃<span style=\"font-weight: bold\"> p25     </span>┃<span style=\"font-weight: bold\"> p50     </span>┃<span style=\"font-weight: bold\"> p75      </span>┃<span style=\"font-weight: bold\"> p100   </span>┃<span style=\"font-weight: bold\"> hist   </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">study_id     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     5.839</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.032</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      10</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    12</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█▂▂▃▁▅</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">age_years    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.0005131</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9995</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -2.415</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.69</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.04942</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.7889</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.453</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▂▄▇█▆▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">gender_male_1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.587e-16</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.832</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.832</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.832</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1.202</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.202</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▆</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">bmi          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.02028</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9147</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -2.196</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5491</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1485</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.4448</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  10.1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █▇  </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">sod          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-3.847e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.458</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.458</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.458</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.458</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.183</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">history_of_pe</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.923e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2093</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2093</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2093</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.2093</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.779</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █   </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">p            </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">hx_of_recurre</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.001359</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9882</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3375</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3375</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3375</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.3375</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.963</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">nt_pancreatit</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">is           </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pancreatic_sp</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-7.693e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.4246</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.4246</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.4246</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.4246</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.355</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">hincterotomy </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">precut_sphinc</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  1.01e-16</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3644</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3644</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3644</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.3644</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 2.744</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">terotomy     </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">minor_papilla</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.06164</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.7141</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.261</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.157</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █   </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">_sphincteroto</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">my           </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">failed_cannul</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.0008837</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.882</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2216</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2216</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2216</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.2216</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.513</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █   </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ation        </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">difficult_can</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.0001433</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9993</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6457</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6457</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6457</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1.549</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.549</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▃</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">nulation     </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pneumatic_dil</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.00106</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9396</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1328</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1328</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1328</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.1328</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 7.528</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █   </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ation_of_inta</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ct_biliary_sp</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">hincter      </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pancreatic_du</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -4.38e-05</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5069</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5069</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5069</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.5069</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.973</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ct_injection </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pancreatic_du</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.01265</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9973</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2635</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2635</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.2635</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.2635</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.796</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ct_injections</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">_2           </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">acinarization</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.001378</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9908</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1809</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1809</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.1809</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.1809</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 5.529</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  █   </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">trainee_invol</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-9.617e-18</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5907</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5907</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5907</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1.693</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.693</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▃</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">vement       </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">cholecystecto</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.02876</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9044</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6011</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6011</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6011</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.3048</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.664</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█▁   ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">my           </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pancreo_bilia</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  5.77e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3073</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3073</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3073</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.3073</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.254</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ry_malignancy</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">guidewire_can</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   -0.1791</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.077</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -3.777</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.2648</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.2648</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.2648</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.2648</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▁    █</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">nulation     </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">guidewire_pas</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.08132</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.8741</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.751</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.751</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3345</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1.123</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.332</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█▂▁▁▁▅</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">sage_into_pan</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">creatic_duct </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">guidewire_pas</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1087</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.9143</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3296</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3296</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3296</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.006759</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.034</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█▁   ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">sage_into_pan</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">creatic_duct_</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">2            </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">biliary_sphin</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  -0.00151</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.8489</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -1.668</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3073</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.5996</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.5996</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.5996</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▂  ▁▂█</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">cterotomy    </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">indomethacin_</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 7.897e-05</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -1.467</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -1.467</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.6817</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  0.6817</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.6817</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▄    █</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">nsaid_prophyl</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">axis         </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">aggressive_hy</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  5.77e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3148</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3148</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.3148</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.3148</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.176</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">dration      </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pancreatic_du</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 4.808e-17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5365</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5365</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.5365</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> -0.5365</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 1.864</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">█    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ct_stent_plac</span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ement        </span> │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">patient_id   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      3694</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  2134</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   1846</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   3678</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    5526</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  7388</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">██████</span> │  │\n",
       "│ └───────────────┴────┴──────┴────────────┴────────┴─────────┴─────────┴─────────┴──────────┴────────┴────────┘  │\n",
       "│ <span style=\"font-style: italic\">                                                   category                                                   </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column                 </span>┃<span style=\"font-weight: bold\"> NA         </span>┃<span style=\"font-weight: bold\"> NA %             </span>┃<span style=\"font-weight: bold\"> ordered                   </span>┃<span style=\"font-weight: bold\"> unique                </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">pep                   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">               0</span> │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">False                    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                    2</span> │  │\n",
       "│ └────────────────────────┴────────────┴──────────────────┴───────────────────────────┴───────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m \u001b[3m       Categories        \u001b[0m                                │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓ ┏━━━━━━━━━━━━━━━━━━━━━━━┓                                │\n",
       "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mDataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mCategorical Variables\u001b[0m\u001b[1;36m \u001b[0m┃                                │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩ ┡━━━━━━━━━━━━━━━━━━━━━━━┩                                │\n",
       "│ │ Number of rows    │ 5911   │ │ float64     │ 25    │ │ pep                   │                                │\n",
       "│ │ Number of columns │ 28     │ │ int64       │ 2     │ └───────────────────────┘                                │\n",
       "│ └───────────────────┴────────┘ │ category    │ 1     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist  \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mstudy_id     \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     5.839\u001b[0m │ \u001b[36m 4.032\u001b[0m │ \u001b[36m      1\u001b[0m │ \u001b[36m      2\u001b[0m │ \u001b[36m      5\u001b[0m │ \u001b[36m      10\u001b[0m │ \u001b[36m    12\u001b[0m │ \u001b[32m█▂▂▃▁▅\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mage_years    \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 0.0005131\u001b[0m │ \u001b[36m0.9995\u001b[0m │ \u001b[36m -2.415\u001b[0m │ \u001b[36m  -0.69\u001b[0m │ \u001b[36m0.04942\u001b[0m │ \u001b[36m  0.7889\u001b[0m │ \u001b[36m 2.453\u001b[0m │ \u001b[32m▂▄▇█▆▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mgender_male_1\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 1.587e-16\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m -0.832\u001b[0m │ \u001b[36m -0.832\u001b[0m │ \u001b[36m -0.832\u001b[0m │ \u001b[36m   1.202\u001b[0m │ \u001b[36m 1.202\u001b[0m │ \u001b[32m█    ▆\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mbmi          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.02028\u001b[0m │ \u001b[36m0.9147\u001b[0m │ \u001b[36m -2.196\u001b[0m │ \u001b[36m-0.5491\u001b[0m │ \u001b[36m-0.1485\u001b[0m │ \u001b[36m  0.4448\u001b[0m │ \u001b[36m  10.1\u001b[0m │ \u001b[32m  █▇  \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141msod          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m-3.847e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m -0.458\u001b[0m │ \u001b[36m -0.458\u001b[0m │ \u001b[36m -0.458\u001b[0m │ \u001b[36m  -0.458\u001b[0m │ \u001b[36m 2.183\u001b[0m │ \u001b[32m█    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mhistory_of_pe\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 1.923e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.2093\u001b[0m │ \u001b[36m-0.2093\u001b[0m │ \u001b[36m-0.2093\u001b[0m │ \u001b[36m -0.2093\u001b[0m │ \u001b[36m 4.779\u001b[0m │ \u001b[32m  █   \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mp            \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mhx_of_recurre\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m -0.001359\u001b[0m │ \u001b[36m0.9882\u001b[0m │ \u001b[36m-0.3375\u001b[0m │ \u001b[36m-0.3375\u001b[0m │ \u001b[36m-0.3375\u001b[0m │ \u001b[36m -0.3375\u001b[0m │ \u001b[36m 2.963\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mnt_pancreatit\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mis           \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpancreatic_sp\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m-7.693e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.4246\u001b[0m │ \u001b[36m-0.4246\u001b[0m │ \u001b[36m-0.4246\u001b[0m │ \u001b[36m -0.4246\u001b[0m │ \u001b[36m 2.355\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mhincterotomy \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mprecut_sphinc\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  1.01e-16\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.3644\u001b[0m │ \u001b[36m-0.3644\u001b[0m │ \u001b[36m-0.3644\u001b[0m │ \u001b[36m -0.3644\u001b[0m │ \u001b[36m 2.744\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mterotomy     \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mminor_papilla\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  -0.06164\u001b[0m │ \u001b[36m0.7141\u001b[0m │ \u001b[36m -0.261\u001b[0m │ \u001b[36m -0.261\u001b[0m │ \u001b[36m -0.261\u001b[0m │ \u001b[36m  -0.261\u001b[0m │ \u001b[36m 4.157\u001b[0m │ \u001b[32m  █   \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141m_sphincteroto\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mmy           \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mfailed_cannul\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 0.0008837\u001b[0m │ \u001b[36m 0.882\u001b[0m │ \u001b[36m-0.2216\u001b[0m │ \u001b[36m-0.2216\u001b[0m │ \u001b[36m-0.2216\u001b[0m │ \u001b[36m -0.2216\u001b[0m │ \u001b[36m 4.513\u001b[0m │ \u001b[32m  █   \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mation        \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mdifficult_can\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 0.0001433\u001b[0m │ \u001b[36m0.9993\u001b[0m │ \u001b[36m-0.6457\u001b[0m │ \u001b[36m-0.6457\u001b[0m │ \u001b[36m-0.6457\u001b[0m │ \u001b[36m   1.549\u001b[0m │ \u001b[36m 1.549\u001b[0m │ \u001b[32m█    ▃\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mnulation     \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpneumatic_dil\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.00106\u001b[0m │ \u001b[36m0.9396\u001b[0m │ \u001b[36m-0.1328\u001b[0m │ \u001b[36m-0.1328\u001b[0m │ \u001b[36m-0.1328\u001b[0m │ \u001b[36m -0.1328\u001b[0m │ \u001b[36m 7.528\u001b[0m │ \u001b[32m  █   \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mation_of_inta\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mct_biliary_sp\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mhincter      \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpancreatic_du\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m -4.38e-05\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.5069\u001b[0m │ \u001b[36m-0.5069\u001b[0m │ \u001b[36m-0.5069\u001b[0m │ \u001b[36m -0.5069\u001b[0m │ \u001b[36m 1.973\u001b[0m │ \u001b[32m█    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mct_injection \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpancreatic_du\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.01265\u001b[0m │ \u001b[36m0.9973\u001b[0m │ \u001b[36m-0.2635\u001b[0m │ \u001b[36m-0.2635\u001b[0m │ \u001b[36m-0.2635\u001b[0m │ \u001b[36m -0.2635\u001b[0m │ \u001b[36m 3.796\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mct_injections\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141m_2           \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141macinarization\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m -0.001378\u001b[0m │ \u001b[36m0.9908\u001b[0m │ \u001b[36m-0.1809\u001b[0m │ \u001b[36m-0.1809\u001b[0m │ \u001b[36m-0.1809\u001b[0m │ \u001b[36m -0.1809\u001b[0m │ \u001b[36m 5.529\u001b[0m │ \u001b[32m  █   \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mtrainee_invol\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m-9.617e-18\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.5907\u001b[0m │ \u001b[36m-0.5907\u001b[0m │ \u001b[36m-0.5907\u001b[0m │ \u001b[36m   1.693\u001b[0m │ \u001b[36m 1.693\u001b[0m │ \u001b[32m█    ▃\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mvement       \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mcholecystecto\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  -0.02876\u001b[0m │ \u001b[36m0.9044\u001b[0m │ \u001b[36m-0.6011\u001b[0m │ \u001b[36m-0.6011\u001b[0m │ \u001b[36m-0.6011\u001b[0m │ \u001b[36m  0.3048\u001b[0m │ \u001b[36m 1.664\u001b[0m │ \u001b[32m█▁   ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mmy           \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpancreo_bilia\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  5.77e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.3073\u001b[0m │ \u001b[36m-0.3073\u001b[0m │ \u001b[36m-0.3073\u001b[0m │ \u001b[36m -0.3073\u001b[0m │ \u001b[36m 3.254\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mry_malignancy\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mguidewire_can\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   -0.1791\u001b[0m │ \u001b[36m 1.077\u001b[0m │ \u001b[36m -3.777\u001b[0m │ \u001b[36m 0.2648\u001b[0m │ \u001b[36m 0.2648\u001b[0m │ \u001b[36m  0.2648\u001b[0m │ \u001b[36m0.2648\u001b[0m │ \u001b[32m▁    █\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mnulation     \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mguidewire_pas\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.08132\u001b[0m │ \u001b[36m0.8741\u001b[0m │ \u001b[36m -0.751\u001b[0m │ \u001b[36m -0.751\u001b[0m │ \u001b[36m-0.3345\u001b[0m │ \u001b[36m   1.123\u001b[0m │ \u001b[36m 1.332\u001b[0m │ \u001b[32m█▂▁▁▁▅\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141msage_into_pan\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mcreatic_duct \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mguidewire_pas\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.1087\u001b[0m │ \u001b[36m0.9143\u001b[0m │ \u001b[36m-0.3296\u001b[0m │ \u001b[36m-0.3296\u001b[0m │ \u001b[36m-0.3296\u001b[0m │ \u001b[36m0.006759\u001b[0m │ \u001b[36m 3.034\u001b[0m │ \u001b[32m█▁   ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141msage_into_pan\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mcreatic_duct_\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141m2            \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mbiliary_sphin\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  -0.00151\u001b[0m │ \u001b[36m0.8489\u001b[0m │ \u001b[36m -1.668\u001b[0m │ \u001b[36m-0.3073\u001b[0m │ \u001b[36m 0.5996\u001b[0m │ \u001b[36m  0.5996\u001b[0m │ \u001b[36m0.5996\u001b[0m │ \u001b[32m▂  ▁▂█\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mcterotomy    \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mindomethacin_\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 7.897e-05\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m -1.467\u001b[0m │ \u001b[36m -1.467\u001b[0m │ \u001b[36m 0.6817\u001b[0m │ \u001b[36m  0.6817\u001b[0m │ \u001b[36m0.6817\u001b[0m │ \u001b[32m▄    █\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mnsaid_prophyl\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141maxis         \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141maggressive_hy\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m  5.77e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.3148\u001b[0m │ \u001b[36m-0.3148\u001b[0m │ \u001b[36m-0.3148\u001b[0m │ \u001b[36m -0.3148\u001b[0m │ \u001b[36m 3.176\u001b[0m │ \u001b[32m█    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mdration      \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpancreatic_du\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m 4.808e-17\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-0.5365\u001b[0m │ \u001b[36m-0.5365\u001b[0m │ \u001b[36m-0.5365\u001b[0m │ \u001b[36m -0.5365\u001b[0m │ \u001b[36m 1.864\u001b[0m │ \u001b[32m█    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mct_stent_plac\u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mement        \u001b[0m │    │      │            │        │         │         │         │          │        │        │  │\n",
       "│ │ \u001b[38;5;141mpatient_id   \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      3694\u001b[0m │ \u001b[36m  2134\u001b[0m │ \u001b[36m      2\u001b[0m │ \u001b[36m   1846\u001b[0m │ \u001b[36m   3678\u001b[0m │ \u001b[36m    5526\u001b[0m │ \u001b[36m  7388\u001b[0m │ \u001b[32m██████\u001b[0m │  │\n",
       "│ └───────────────┴────┴──────┴────────────┴────────┴─────────┴─────────┴─────────┴──────────┴────────┴────────┘  │\n",
       "│ \u001b[3m                                                   category                                                   \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mordered                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1munique               \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mpep                   \u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m               0\u001b[0m │ \u001b[38;5;45mFalse                    \u001b[0m │ \u001b[36m                    2\u001b[0m │  │\n",
       "│ └────────────────────────┴────────────┴──────────────────┴───────────────────────────┴───────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Applying imputation to whole dataset to test stats:\")\n",
    "imputed_final = impute_values(train, test)\n",
    "train_imputed_final = imputed_final['train'] \n",
    "test_imputed_final = imputed_final['test']\n",
    "\n",
    "print(f\"  Train: {train_imputed_final.shape}, missing: {train_imputed_final.select_dtypes(include=[np.number]).isnull().sum().sum()}\")\n",
    "print(f\"  Test: {test_imputed_final.shape}, missing: {test_imputed_final.select_dtypes(include=[np.number]).isnull().sum().sum()}\")\n",
    "\n",
    "skim(train_imputed_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292be31",
   "metadata": {},
   "source": [
    "## Train main GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7fb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data = train_imputed_final.copy()\n",
    "final_test_data = test_imputed_final.copy()\n",
    "\n",
    "# Generate folds using the training data dimensions\n",
    "X = final_train_data.drop(['pep', 'patient_id', 'study_id'], axis=1)\n",
    "y = final_train_data['pep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eedbda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1...\n",
      "Starting imputation with train shape: (4728, 25), test shape: (1183, 25)\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (4728, 25), test (1183, 25)\n",
      "Fold 2...\n",
      "Starting imputation with train shape: (4729, 25), test shape: (1182, 25)\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (4729, 25), test (1182, 25)\n",
      "Fold 3...\n",
      "Starting imputation with train shape: (4729, 25), test shape: (1182, 25)\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (4729, 25), test (1182, 25)\n",
      "Fold 4...\n",
      "Starting imputation with train shape: (4729, 25), test shape: (1182, 25)\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (4729, 25), test (1182, 25)\n",
      "Fold 5...\n",
      "Starting imputation with train shape: (4729, 25), test shape: (1182, 25)\n",
      "  Cleaned mixed data types\n",
      "  Found 25 numeric columns for processing\n",
      "  Imputation completed\n",
      "  Final shapes: train (4729, 25), test (1182, 25)\n",
      "Cohen's Kappa: 0.0\n",
      "AUC: 0.6864748739024845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# R: set.seed(229)\n",
    "np.random.seed(229)\n",
    "\n",
    "# 5-fold stratified CV, no repeats\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=229)\n",
    "\n",
    "pred_list = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Fold {i}...\")\n",
    "    \n",
    "    # Equiv: dt %>% slice(-test_index[[i]]) and slice(test_index[[i]])\n",
    "    X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "    y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "    test_ids = final_train_data.iloc[test_idx][\"patient_id\"].values\n",
    "\n",
    "    # Impute values\n",
    "    imputed = impute_values(X_train, X_test, new_dataset=False)\n",
    "    X_train_imputed = imputed['train']\n",
    "    X_test_imputed = imputed['test']\n",
    "\n",
    "    # Train model\n",
    "    # caret::gbm uses Gaussian deviance, 100 trees, shrinkage=0.1, interaction.depth=1 by default\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=1,\n",
    "        random_state=229\n",
    "    )\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "\n",
    "    # Predict probabilities for positive class\n",
    "    pred_prob = model.predict_proba(X_test_imputed)[:, 1]\n",
    "\n",
    "    # Save predictions\n",
    "    fold_df = pd.DataFrame({\n",
    "        \"pred\": pred_prob,\n",
    "        \"y\": y_test.values,\n",
    "        \"patient_id\": test_ids\n",
    "    })\n",
    "    pred_list.append(fold_df)\n",
    "\n",
    "pred_df = pd.concat(pred_list, ignore_index=True)\n",
    "\n",
    "# Compute Kappa (for completeness)\n",
    "#* R fitControl had only one repeat and no tuning grid defined, the effective training is just a single fit\n",
    "y_pred_bin = (pred_df[\"pred\"] > 0.5).astype(int)\n",
    "kappa = cohen_kappa_score(pred_df[\"y\"], y_pred_bin)\n",
    "print(\"Cohen's Kappa:\", kappa)\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(pred_df[\"y\"], pred_df[\"pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5983f7",
   "metadata": {},
   "source": [
    "**R result:** Area under the curve: 0.6914\n",
    "\n",
    "AUC (all): 0.6913554 \n",
    "\n",
    "AUC (no trt): 0.641093 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95fba690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(pred_df[\"y\"], pred_df[\"pred\"])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC GBM, all')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb2663",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Luo dataset (study_id == \"2\" in new datasheet, but study_id == \"3\" in old_dat)\u001b[39;00m\n\u001b[32m      8\u001b[39m study_3 = old_dat.query(\u001b[33m\"\u001b[39m\u001b[33mstudy == 3\u001b[39m\u001b[33m\"\u001b[39m).copy()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m ids_study2 = dt.loc[dt[\u001b[33m\"\u001b[39m\u001b[33mstudy_id\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpatient_id\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m     11\u001b[39m n = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(study_3), \u001b[38;5;28mlen\u001b[39m(ids_study2))\n\u001b[32m     12\u001b[39m study_3 = study_3.iloc[:n].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pep/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_tuple(key)\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pep/lib/python3.11/site-packages/pandas/core/indexing.py:1368\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[32m   1367\u001b[39m     tup = \u001b[38;5;28mself\u001b[39m._expand_ellipsis(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_lowerdim(tup)\n\u001b[32m   1370\u001b[39m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[32m   1371\u001b[39m tup = \u001b[38;5;28mself\u001b[39m._validate_tuple_indexer(tup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pep/lib/python3.11/site-packages/pandas/core/indexing.py:1089\u001b[39m, in \u001b[36m_LocationIndexer._getitem_lowerdim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1087\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m section\n\u001b[32m   1088\u001b[39m         \u001b[38;5;66;03m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(section, \u001b[38;5;28mself\u001b[39m.name)[new_key]\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[33m\"\u001b[39m\u001b[33mnot applicable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pep/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_axis(maybe_callable, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pep/lib/python3.11/site-packages/pandas/core/indexing.py:1418\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_iterable(key, axis=axis)\n\u001b[32m   1422\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "# ROC for no treatment patients only \n",
    "\"\"\"\n",
    "old_dat = read_csv(here(\"../data/Risk Factors INDIEH Elmunzer Luo version Albert.csv\")) # To extract high_risk column for study 3\n",
    "# Luo dataset (study_id == \"2\" in new datasheet, but study_id == \"3\" in old_dat)\n",
    "study_3 = old_dat %>%\n",
    "  filter(study == 3) %>%\n",
    "  mutate(patient_id = dt %>% filter(study_id == 2) %>% pull(patient_id)) %>% # Order of samples must be the same\n",
    "  select(patient_id, high_risk_patients)\n",
    "trt_randomized_groups = dt %>%\n",
    "  left_join(., study_3, by = \"patient_id\") %>%\n",
    "  mutate(trt_ah = (study_id %in% c(5, 6, 11)),\n",
    "         trt_indo = (study_id %in% c(1, 3, 4, 7)) | (study_id == 2 & high_risk_patients == 0),\n",
    "         trt_ah_indo = (study_id %in% c(5, 6, 7)),\n",
    "         trt_pd = (study_id %in% c(1, 2, 3, 4, 5, 7, 9)),\n",
    "         trt_indo_pd = (study_id %in% c(1, 3, 4, 7)) | (study_id == 2 & high_risk_patients == 0)) %>%\n",
    "  select(patient_id, trt_ah, trt_indo, trt_ah_indo, trt_pd, trt_indo_pd)\n",
    "saveRDS(trt_randomized_groups, here(\"../data/trt_randomized_groups.rds\"))\n",
    "\n",
    "no_trt_patients = dt %>% filter(!(indomethacin_nsaid_prophylaxis == 1 | aggressive_hydration == 1 | pancreatic_duct_stent_placement == 1)) %>% pull(patient_id)\n",
    "\n",
    "# ROC for all patients - BOOSTED TREE\n",
    "roc_dt_all = get_performance(pred_dt) %>%\n",
    "  mutate(subset = \"all\")\n",
    "\n",
    "# ROC for no treatment patients only\n",
    "pred_dt_notrt = pred_dt %>%\n",
    "  filter(patient_id %in% no_trt_patients)\n",
    "\n",
    "roc_dt_notrt = get_performance(pred_dt_notrt) %>%\n",
    "mutate(subset = \"no trt\")\n",
    "\n",
    "cat(\"AUC (all):\", unique(roc_dt_all$auc), \"\\n\") # EMILY EVAL\n",
    "cat(\"AUC (no trt):\", unique(roc_dt_notrt$auc), \"\\n\")\n",
    "\"\"\"\n",
    "old_dat = pd.read_csv(\"../../data/Risk Factors INDIEH Elmunzer Luo version Albert.csv\")\n",
    "study_3 = (\n",
    "    old_dat.query(\"study == 3\")\n",
    "    .assign(patient_id=lambda df: dt.loc[dt[\"study_id\"] == 2, \"patient_id\"].values)\n",
    "    [[\"patient_id\", \"high_risk_patients\"]]\n",
    ")\n",
    "trt_randomized_groups = (\n",
    "    dt.merge(study_3, on=\"patient_id\", how=\"left\")\n",
    "    .assign(\n",
    "        trt_ah=lambda d: d[\"study_id\"].isin([5, 6, 11]),\n",
    "        trt_indo=lambda d: d[\"study_id\"].isin([1, 3, 4, 7]) |\n",
    "                           ((d[\"study_id\"] == 2) & (d[\"high_risk_patients\"] == 0)),\n",
    "        trt_ah_indo=lambda d: d[\"study_id\"].isin([5, 6, 7]),\n",
    "        trt_pd=lambda d: d[\"study_id\"].isin([1, 2, 3, 4, 5, 7, 9]),\n",
    "        trt_indo_pd=lambda d: d[\"study_id\"].isin([1, 3, 4, 7]) |\n",
    "                              ((d[\"study_id\"] == 2) & (d[\"high_risk_patients\"] == 0))\n",
    "    )[[\"patient_id\", \"trt_ah\", \"trt_indo\", \"trt_ah_indo\", \"trt_pd\", \"trt_indo_pd\"]]\n",
    ")\n",
    "# trt_randomized_groups.to_pickle(\"../data/trt_randomized_groups.pkl\") # saveRDS(trt_randomized_groups, here(\"../data/trt_randomized_groups.rds\"))\n",
    "\n",
    "# No treamtent patients\n",
    "no_trt_patients = dt.loc[~(\n",
    "        (dt[\"indomethacin_nsaid_prophylaxis\"] == 1) |\n",
    "        (dt[\"aggressive_hydration\"] == 1) |\n",
    "        (dt[\"pancreatic_duct_stent_placement\"] == 1)\n",
    "    ), \"patient_id\"].tolist()\n",
    "print(f\"No treatment patients: {len(no_trt_patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute AUC for all patients ---\n",
    "roc_dt_all = pd.DataFrame({\n",
    "    \"auc\": [roc_auc_score(pred_df[\"y\"], pred_df[\"pred\"])],\n",
    "    \"subset\": [\"all\"]\n",
    "})\n",
    "\n",
    "# --- Compute AUC for no-treatment patients only ---\n",
    "pred_dt_notrt = pred_df[pred_df[\"patient_id\"].isin(no_trt_patients)].copy()\n",
    "roc_dt_notrt = pd.DataFrame({\n",
    "    \"auc\": [roc_auc_score(pred_dt_notrt[\"y\"], pred_dt_notrt[\"pred\"])],\n",
    "    \"subset\": [\"no trt\"]\n",
    "})\n",
    "\n",
    "# --- Display results ---\n",
    "print(f\"AUC (all): {roc_dt_all['auc'].iloc[0]:.3f}\")\n",
    "print(f\"AUC (no trt): {roc_dt_notrt['auc'].iloc[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44418c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final validation\n",
    "# max_train_idx = max([max(train_idx) for train_idx, _ in fold_indices])\n",
    "# max_val_idx = max([max(val_idx) for _, val_idx in fold_indices])\n",
    "# print(f\"\\n   Final validation: max_train_idx={max_train_idx}, max_val_idx={max_val_idx}\")\n",
    "# print(f\"   Training data size: {len(final_train_data)}\")\n",
    "\n",
    "# if max_train_idx < len(final_train_data) and max_val_idx < len(final_train_data):    \n",
    "#     # Grid search parameters (matching R caret tune grid exactly)\n",
    "#     param_grid = {\n",
    "#         'max_depth': [1, 2, 3],  # depth\n",
    "#         'n_estimators': [50, 100, 150],  # trees  \n",
    "#         'learning_rate': [0.1],  # lr\n",
    "#         'min_samples_split': [10]  # min_split\n",
    "#     }\n",
    "\n",
    "#     # Generate all combinations\n",
    "#     depth_vals = param_grid['max_depth']\n",
    "#     trees_vals = param_grid['n_estimators'] \n",
    "#     lr_vals = param_grid['learning_rate']\n",
    "#     split_vals = param_grid['min_samples_split']\n",
    "\n",
    "#     all_combinations = [(d, t, lr, s) for d in depth_vals for t in trees_vals for lr in lr_vals for s in split_vals]\n",
    "\n",
    "#     print(f\"\\n🎯 STARTING GRID SEARCH...\")\n",
    "#     print(f\"Testing {len(all_combinations)} parameter combinations\")\n",
    "\n",
    "#     # Main grid search loop\n",
    "#     all_results = []\n",
    "\n",
    "#     for combo_idx, (depth, trees, lr, min_split) in enumerate(all_combinations, 1):\n",
    "#         print(f\"\\nTesting combination {combo_idx}/{len(all_combinations)}: depth={depth}, trees={trees}\")\n",
    "        \n",
    "#         # Store fold results for this parameter combination\n",
    "#         fold_kappas = []\n",
    "        \n",
    "#         for fold_idx, (cv_train_idx, cv_test_idx) in enumerate(fold_indices):\n",
    "#             # Get fold data from training set\n",
    "#             cv_train_fold = final_train_data.iloc[cv_train_idx].copy()\n",
    "#             cv_test_fold = final_train_data.iloc[cv_test_idx].copy()\n",
    "            \n",
    "#             # Impute values independently for this fold (matching R exactly)\n",
    "#             imputed_fold = impute_values(cv_train_fold, cv_test_fold, new_dataset=(fold_idx == 0 and combo_idx == 1))\n",
    "#             cv_train_imputed = imputed_fold['train']\n",
    "#             cv_test_imputed = imputed_fold['test']\n",
    "#             current_feature_cols = imputed_fold['feature_cols']  # Get the actual numeric feature columns\n",
    "            \n",
    "#             # Prepare features and target using the validated feature columns\n",
    "#             X_cv_train = cv_train_imputed[current_feature_cols]\n",
    "#             y_cv_train = cv_train_imputed['pep'].astype(int)\n",
    "#             X_cv_test = cv_test_imputed[current_feature_cols]  \n",
    "#             y_cv_test = cv_test_imputed['pep'].astype(int)\n",
    "            \n",
    "#             # Verify data is clean before model training\n",
    "#             if X_cv_train.select_dtypes(include=['object']).shape[1] > 0:\n",
    "#                 print(f\"   ⚠️  WARNING: Found object columns in training data for fold {fold_idx+1}\")\n",
    "#                 continue\n",
    "                \n",
    "#             # Train model for this fold\n",
    "#             fold_model = GradientBoostingClassifier(\n",
    "#                 max_depth=depth,\n",
    "#                 n_estimators=trees,\n",
    "#                 learning_rate=lr,\n",
    "#                 min_samples_split=min_split,\n",
    "#                 random_state=1,\n",
    "#                 verbose=0\n",
    "#             )\n",
    "            \n",
    "#             fold_model.fit(X_cv_train, y_cv_train)\n",
    "            \n",
    "#             # Predict on validation fold\n",
    "#             cv_pred_proba = fold_model.predict_proba(X_cv_test)[:, 1]\n",
    "#             cv_pred_class = (cv_pred_proba > 0.5).astype(int)\n",
    "            \n",
    "#             # Calculate Kappa (matching R's metric)\n",
    "#             from sklearn.metrics import cohen_kappa_score\n",
    "#             fold_kappa = cohen_kappa_score(y_cv_test, cv_pred_class)\n",
    "#             fold_kappas.append(fold_kappa)\n",
    "        \n",
    "#         # Store results for this parameter combination\n",
    "#         import numpy as np\n",
    "#         mean_kappa = np.mean(fold_kappas) if fold_kappas else 0.0\n",
    "#         std_kappa = np.std(fold_kappas) if fold_kappas else 0.0\n",
    "\n",
    "#         result = {\n",
    "#             'max_depth': depth,\n",
    "#             'n_estimators': trees, \n",
    "#             'learning_rate': lr,\n",
    "#             'min_samples_split': min_split,\n",
    "#             'mean_kappa': mean_kappa,\n",
    "#             'std_kappa': std_kappa,\n",
    "#             'fold_kappas': fold_kappas\n",
    "#         }\n",
    "#         all_results.append(result)\n",
    "        \n",
    "#         print(f\"   Mean Kappa: {mean_kappa:.4f} ± {std_kappa:.4f}\")\n",
    "\n",
    "#     print(f\"\\n✅ Grid search completed with {len(all_results)} parameter combinations!\")\n",
    "#     print(f\"   Using {len(current_feature_cols)} numeric features (type_of_sod excluded)\")\n",
    "    \n",
    "#     # Update global feature_cols for subsequent cells\n",
    "#     feature_cols = current_feature_cols\n",
    "    \n",
    "# else:\n",
    "#     print(\"   ❌ Fold indices are still invalid!\")\n",
    "#     print(\"   Cannot proceed with grid search.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6d3834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETER OPTIMIZATION RESULTS:\n",
      "============================================================\n",
      "Total combinations tested: 9\n",
      "\n",
      "Top 5 parameter combinations by Kappa score:\n",
      "   max_depth  n_estimators  learning_rate  min_samples_split  mean_kappa  \\\n",
      "8          3           150            0.1                 10    0.026149   \n",
      "7          3           100            0.1                 10    0.024387   \n",
      "6          3            50            0.1                 10    0.017767   \n",
      "5          2           150            0.1                 10    0.009157   \n",
      "4          2           100            0.1                 10    0.007679   \n",
      "\n",
      "   std_kappa  \n",
      "8   0.038843  \n",
      "7   0.023044  \n",
      "6   0.021237  \n",
      "5   0.008946  \n",
      "4   0.010377  \n",
      "\n",
      "BEST PARAMETERS:\n",
      "   Max depth: 3\n",
      "   N estimators: 150\n",
      "   Learning rate: 0.1\n",
      "   Min samples split: 10\n",
      "   Cross-validation Kappa: 0.0261\n",
      "\n",
      "✅ Ready to train final model with best parameters!\n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('mean_kappa', ascending=False)\n",
    "\n",
    "print(\"HYPERPARAMETER OPTIMIZATION RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total combinations tested: {len(results_df)}\")\n",
    "print(\"\\nTop 5 parameter combinations by Kappa score:\")\n",
    "print(results_df[['max_depth', 'n_estimators', 'learning_rate', 'min_samples_split', 'mean_kappa', 'std_kappa']].head())\n",
    "\n",
    "# Get best parameters\n",
    "best_result = results_df.iloc[0]\n",
    "best_params = {\n",
    "    'max_depth': int(best_result['max_depth']),\n",
    "    'n_estimators': int(best_result['n_estimators']),\n",
    "    'learning_rate': best_result['learning_rate'],\n",
    "    'min_samples_split': int(best_result['min_samples_split']),\n",
    "    'mean_kappa': best_result['mean_kappa']\n",
    "}\n",
    "\n",
    "print(f\"\\nBEST PARAMETERS:\")\n",
    "print(f\"   Max depth: {best_params['max_depth']}\")\n",
    "print(f\"   N estimators: {best_params['n_estimators']}\")\n",
    "print(f\"   Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"   Min samples split: {best_params['min_samples_split']}\")\n",
    "print(f\"   Cross-validation Kappa: {best_params['mean_kappa']:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Ready to train final model with best parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea24ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 TRAINING FINAL MODEL WITH BEST PARAMETERS...\n",
      "Applying final imputation to training and test sets...\n",
      "✅ Imputation complete:\n",
      "   - Converted '.' to NaN and ensured numeric types\n",
      "   - Applied study-specific rules\n",
      "   - Centered and scaled 27 numeric features\n",
      "   - KNN imputation (k=10)\n",
      "   - ✅ type_of_sod excluded (matching R: high missingness, redundant with sod)\n",
      "   - Missing values after imputation: train=0, test=0\n",
      "   - String columns remaining: train=0, test=0\n",
      "✅ Final model trained successfully!\n",
      "   Test AUC: 0.6640\n",
      "   Model type: GradientBoostingClassifier\n",
      "   Features: 27 (type_of_sod excluded)\n",
      "\n",
      "Top 10 most important features:\n",
      "            feature  importance\n",
      "2               bmi    0.184011\n",
      "21        gw_passpd    0.154706\n",
      "0         age_years    0.135137\n",
      "16         panc_div    0.043329\n",
      "26         pd_stent    0.040557\n",
      "8    min_pap_sphinc    0.036034\n",
      "14          acinarz    0.035392\n",
      "18          cholecy    0.030373\n",
      "4    history_of_pep    0.027611\n",
      "15  panc_brush_cyto    0.027344\n"
     ]
    }
   ],
   "source": [
    "# Train final model on full training data with proper imputation\n",
    "print(f\"\\n🔧 TRAINING FINAL MODEL WITH BEST PARAMETERS...\")\n",
    "\n",
    "# Apply imputation to full training and test sets\n",
    "print(\"Applying final imputation to training and test sets...\")\n",
    "final_imputed = impute_values(final_train_data, final_test_data, new_dataset=True)\n",
    "train_imputed_final = final_imputed['train']\n",
    "test_imputed_final = final_imputed['test']\n",
    "\n",
    "# Prepare final features and target\n",
    "X_train_final = train_imputed_final[feature_cols]\n",
    "y_train_final = train_imputed_final['pep'].astype(int)\n",
    "X_test_final = test_imputed_final[feature_cols]\n",
    "y_test_final = test_imputed_final['pep'].astype(int)\n",
    "\n",
    "# Train final model\n",
    "main_gbm_model = GradientBoostingClassifier(\n",
    "    max_depth=best_params['max_depth'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    random_state=1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "main_gbm_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_pred_proba = main_gbm_model.predict_proba(X_test_final)[:, 1]\n",
    "final_auc = roc_auc_score(y_test_final, test_pred_proba)\n",
    "\n",
    "print(f\"✅ Final model trained successfully!\")\n",
    "print(f\"   Test AUC: {final_auc:.4f}\")\n",
    "print(f\"   Model type: GradientBoostingClassifier\") \n",
    "print(f\"   Features: {len(feature_cols)} (type_of_sod excluded)\")\n",
    "\n",
    "# Create feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': main_gbm_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 most important features:\")\n",
    "print(feature_importance[['feature', 'importance']].head(10))\n",
    "\n",
    "# Store results\n",
    "best_main_params = best_params\n",
    "best_main_kappa = best_params['mean_kappa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL MODEL SUMMARY AND VALIDATION\n",
    "\n",
    "# Ensure test data PEP is also numeric\n",
    "final_test_data['pep'] = final_test_data['pep'].astype(int)\n",
    "\n",
    "print(f\"📊 DATASET SUMMARY:\")\n",
    "print(f\"   Total observations: {len(final_train_data) + len(final_test_data)}\")\n",
    "print(f\"   Training samples: {len(final_train_data)} ({len(final_train_data)/(len(final_train_data) + len(final_test_data))*100:.1f}%)\")\n",
    "print(f\"   Test samples: {len(final_test_data)} ({len(final_test_data)/(len(final_train_data) + len(final_test_data))*100:.1f}%)\")\n",
    "print(f\"   PEP rate (train): {final_train_data['pep'].mean():.3f}\")\n",
    "print(f\"   PEP rate (test): {final_test_data['pep'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\n🔧 FEATURE ENGINEERING:\")\n",
    "print(f\"   Total features: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\n🎯 MODEL CONFIGURATION:\")\n",
    "print(f\"   Algorithm: Gradient Boosting Classifier\")\n",
    "print(f\"   Max depth: {best_params['max_depth']}\")\n",
    "print(f\"   N estimators: {best_params['n_estimators']}\")\n",
    "print(f\"   Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"   Min samples split: {best_params['min_samples_split']}\")\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE METRICS:\")\n",
    "print(f\"   Cross-validation Kappa: {best_params['mean_kappa']:.4f}\")\n",
    "print(f\"   Test AUC: {final_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n🔑 TOP 5 FEATURE IMPORTANCE:\")\n",
    "for i, row in feature_importance.head().iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e9a027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 SAVING MODEL AND VALIDATION DATA FOR APP.PY\n",
      "============================================================\n",
      "✅ Main GBM model saved: ../pep_risk_app/data/gbm_model_python.pkl (193.8 KB)\n",
      "✅ Feature importance saved: ../pep_risk_app/data/feature_importance_python.csv\n",
      "✅ Training data saved: ../pep_risk_app/data/train_impute_python.csv (3185.3 KB)\n",
      "\n",
      "🧪 VALIDATION FOR APP.PY COMPATIBILITY:\n",
      "   Model feature count: 27\n",
      "   App feature count: 27\n",
      "   Features match: True\n",
      "   String columns in saved data: 0\n",
      "   ✅ All feature columns are numeric\n",
      "   Missing values: 0\n",
      "   ✅ Model prediction test passed: 0.1519\n",
      "\n",
      "📋 SUMMARY FOR APP.PY UPDATE:\n",
      "   ✅ Model saved with 27 features\n",
      "   ✅ type_of_sod excluded (matching R implementation)\n",
      "   ✅ All data cleaned and numeric\n",
      "   ✅ Ready for app.py integration\n",
      "\n",
      "💡 TO UPDATE APP.PY:\n",
      "   1. Update feature exclusion list to include 'type_of_sod'\n",
      "   2. Add proper string '.' handling in normalize_patient_data()\n",
      "   3. Use the saved model: gbm_model_python.pkl\n",
      "   4. Use the cleaned training data: train_impute_python.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE MODEL AND VALIDATION DATA FOR APP.PY\n",
    "import joblib\n",
    "\n",
    "print(\"SAVING MODEL AND VALIDATION DATA FOR APP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = '../pep_risk_app/data'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the main model\n",
    "model_path = os.path.join(models_dir, 'gbm_model_python.pkl')\n",
    "joblib.dump(main_gbm_model, model_path)\n",
    "print(f\"Main GBM model saved: {model_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_path = os.path.join(models_dir, 'feature_importance_python.csv')\n",
    "feature_importance.to_csv(feature_importance_path, index=False)\n",
    "print(f\"Feature importance saved: {feature_importance_path}\")\n",
    "\n",
    "# Save training data for app reference (cleaned version)\n",
    "train_data_path = os.path.join(models_dir, 'train_impute_python.csv')\n",
    "train_imputed_final.to_csv(train_data_path, index=False)\n",
    "train_size = os.path.getsize(train_data_path) / 1024\n",
    "print(f\"Training data saved: {train_data_path} ({train_size:.1f} KB)\")\n",
    "\n",
    "# Create a test validation to ensure app.py compatibility\n",
    "print(f\"\\n🧪 VALIDATION FOR APP.PY COMPATIBILITY:\")\n",
    "\n",
    "# Test feature columns consistency\n",
    "saved_train = pd.read_csv(train_data_path)\n",
    "app_feature_cols = [col for col in saved_train.columns if col not in ['pep', 'patient_id', 'study_id', 'study', 'type_of_sod', 'pep_severity']]\n",
    "\n",
    "print(f\"   Model feature count: {len(feature_cols)}\")\n",
    "print(f\"   App feature count: {len(app_feature_cols)}\")\n",
    "print(f\"   Features match: {set(feature_cols) == set(app_feature_cols)}\")\n",
    "\n",
    "# Test data type consistency\n",
    "string_cols = saved_train[app_feature_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"   String columns in saved data: {len(string_cols)}\")\n",
    "if len(string_cols) > 0:\n",
    "    print(f\"   WARNING: Found string columns: {string_cols}\")\n",
    "else:\n",
    "    print(f\"   All feature columns are numeric\")\n",
    "\n",
    "# Test for missing values\n",
    "missing_counts = saved_train[app_feature_cols].isnull().sum().sum()\n",
    "print(f\"   Missing values: {missing_counts}\")\n",
    "\n",
    "# Test prediction on a sample\n",
    "sample_data = saved_train[app_feature_cols].iloc[0:1]\n",
    "try:\n",
    "    test_pred = main_gbm_model.predict_proba(sample_data)\n",
    "    print(f\"   ✅ Model prediction test passed: {test_pred[0][1]:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Model prediction test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071b2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED MISSING VALUE CHECK\n",
      "========================================\n",
      "Train imputed shape: (5911, 29)\n",
      "Test imputed shape: (1478, 29)\n",
      "\n",
      "Columns in train_imputed:\n",
      "  minor_papilla_sphincterotomy: 3668 missing\n",
      "  pancreatic_duct_injection: 1 missing\n",
      "  guidewire_passage_into_pancreatic_duct: 3234 missing\n",
      "  guidewire_passage_into_pancreatic_duct_2: 1879 missing\n",
      "  biliary_sphincterotomy: 1971 missing\n",
      "  pep_severity: 825 missing\n",
      "  panc_inj>2: 5911 missing\n",
      "\n",
      "Numeric columns missing check:\n",
      "Total numeric missing: 5911\n",
      "\n",
      "First 3 rows of train_imputed:\n",
      "   age_years  gender_male_1       bmi       sod  history_of_pep  \\\n",
      "0  -1.675979      -0.832011  0.562544  2.183307       -0.209268   \n",
      "1  -2.292192       1.201908 -0.118402 -0.458021       -0.209268   \n",
      "2  -1.121387      -0.832011  0.050392 -0.458021       -0.209268   \n",
      "\n",
      "   hx_of_recurrent_pancreatitis  pancreatic_sphincterotomy  \\\n",
      "0                     -0.337526                  -0.424631   \n",
      "1                      2.962731                   2.354986   \n",
      "2                     -0.337526                   2.354986   \n",
      "\n",
      "   precut_sphincterotomy minor_papilla_sphincterotomy  failed_cannulation  \\\n",
      "0               -0.36443                          NaN            0.251805   \n",
      "1               -0.36443                          NaN            0.251805   \n",
      "2               -0.36443                          NaN           -0.221606   \n",
      "\n",
      "   ...  guidewire_passage_into_pancreatic_duct  \\\n",
      "0  ...                                     NaN   \n",
      "1  ...                                     NaN   \n",
      "2  ...                                     NaN   \n",
      "\n",
      "   guidewire_passage_into_pancreatic_duct_2 biliary_sphincterotomy  \\\n",
      "0                                       NaN                      1   \n",
      "1                                       NaN                      0   \n",
      "2                                       NaN                      0   \n",
      "\n",
      "   indomethacin_nsaid_prophylaxis  aggressive_hydration  \\\n",
      "0                        -1.46697             -0.314813   \n",
      "1                        -1.46697             -0.314813   \n",
      "2                        -1.46697             -0.314813   \n",
      "\n",
      "   pancreatic_duct_stent_placement  pep  pep_severity  patient_id panc_inj>2  \n",
      "0                         1.864039    1           NaN           2        NaN  \n",
      "1                         1.864039    1           NaN           3        NaN  \n",
      "2                         1.864039    1           NaN           4        NaN  \n",
      "\n",
      "[3 rows x 29 columns]\n",
      "\n",
      "Data types:\n",
      "age_years                                          float64\n",
      "gender_male_1                                      float64\n",
      "bmi                                                float64\n",
      "sod                                                float64\n",
      "history_of_pep                                     float64\n",
      "hx_of_recurrent_pancreatitis                       float64\n",
      "pancreatic_sphincterotomy                          float64\n",
      "precut_sphincterotomy                              float64\n",
      "minor_papilla_sphincterotomy                        object\n",
      "failed_cannulation                                 float64\n",
      "difficult_cannulation                              float64\n",
      "pneumatic_dilation_of_intact_biliary_sphincter     float64\n",
      "pancreatic_duct_injection                           object\n",
      "pancreatic_duct_injections_2                       float64\n",
      "acinarization                                      float64\n",
      "trainee_involvement                                float64\n",
      "cholecystectomy                                    float64\n",
      "pancreo_biliary_malignancy                         float64\n",
      "guidewire_cannulation                              float64\n",
      "guidewire_passage_into_pancreatic_duct              object\n",
      "guidewire_passage_into_pancreatic_duct_2            object\n",
      "biliary_sphincterotomy                              object\n",
      "indomethacin_nsaid_prophylaxis                     float64\n",
      "aggressive_hydration                               float64\n",
      "pancreatic_duct_stent_placement                    float64\n",
      "pep                                               category\n",
      "pep_severity                                        object\n",
      "patient_id                                           int64\n",
      "panc_inj>2                                         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the missing values more carefully\n",
    "print(\"DETAILED MISSING VALUE CHECK\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Train imputed shape: {train_imputed.shape}\")\n",
    "print(f\"Test imputed shape: {test_imputed.shape}\")\n",
    "\n",
    "# Check specific columns for missing values\n",
    "print(\"\\nColumns in train_imputed:\")\n",
    "for col in train_imputed.columns:\n",
    "    missing_count = train_imputed[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"  {col}: {missing_count} missing\")\n",
    "\n",
    "print(\"\\nNumeric columns missing check:\")\n",
    "numeric_missing = train_imputed.select_dtypes(include=[np.number]).isnull().sum().sum()\n",
    "print(f\"Total numeric missing: {numeric_missing}\")\n",
    "\n",
    "# Show first few rows to verify\n",
    "print(\"\\nFirst 3 rows of train_imputed:\")\n",
    "print(train_imputed.head(3))\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(train_imputed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "619cee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMINING OBJECT COLUMNS\n",
      "========================================\n",
      "\n",
      "minor_papilla_sphincterotomy:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 0 '1' 1 2]\n",
      "  Missing: 3668\n",
      "\n",
      "pancreatic_duct_injection:\n",
      "  Dtype: object\n",
      "  Unique values: [0 1 nan '0']\n",
      "  Missing: 1\n",
      "\n",
      "guidewire_passage_into_pancreatic_duct:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 1 '1' 0 ' ']\n",
      "  Missing: 3234\n",
      "\n",
      "guidewire_passage_into_pancreatic_duct_2:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 0 1 ' ']\n",
      "  Missing: 1879\n",
      "\n",
      "biliary_sphincterotomy:\n",
      "  Dtype: object\n",
      "  Unique values: [1 0 nan]\n",
      "  Missing: 1971\n",
      "\n",
      "pep_severity:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 1 2 3 0 '2' '1']\n",
      "  Missing: 825\n",
      "\n",
      "CHECKING ORIGINAL DATA\n",
      "==============================\n",
      "\n",
      "minor_papilla_sphincterotomy in original:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 0 '1' 1 2]\n",
      "  Missing: 4572\n",
      "\n",
      "pancreatic_duct_injection in original:\n",
      "  Dtype: object\n",
      "  Unique values: [0 1 nan '0']\n",
      "  Missing: 1\n",
      "\n",
      "guidewire_passage_into_pancreatic_duct in original:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 1 '1' 0 ' ']\n",
      "  Missing: 4038\n",
      "\n",
      "guidewire_passage_into_pancreatic_duct_2 in original:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 0 1 ' ']\n",
      "  Missing: 2358\n",
      "\n",
      "biliary_sphincterotomy in original:\n",
      "  Dtype: object\n",
      "  Unique values: [0 1 nan ' ']\n",
      "  Missing: 2436\n",
      "\n",
      "pep_severity in original:\n",
      "  Dtype: object\n",
      "  Unique values: [nan 1 2 3 0 '2' '1']\n",
      "  Missing: 1052\n"
     ]
    }
   ],
   "source": [
    "# Examine the object columns that weren't imputed\n",
    "print(\"EXAMINING OBJECT COLUMNS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "object_cols = ['minor_papilla_sphincterotomy', 'pancreatic_duct_injection', \n",
    "               'guidewire_passage_into_pancreatic_duct', 'guidewire_passage_into_pancreatic_duct_2', \n",
    "               'biliary_sphincterotomy', 'pep_severity']\n",
    "\n",
    "for col in object_cols:\n",
    "    if col in train_imputed.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Dtype: {train_imputed[col].dtype}\")\n",
    "        print(f\"  Unique values: {train_imputed[col].unique()[:10]}\")  # First 10 unique values\n",
    "        print(f\"  Missing: {train_imputed[col].isnull().sum()}\")\n",
    "\n",
    "# Check original data to see what these should be\n",
    "print(\"\\nCHECKING ORIGINAL DATA\")\n",
    "print(\"=\"*30)\n",
    "for col in object_cols:\n",
    "    if col in dt.columns:\n",
    "        print(f\"\\n{col} in original:\")\n",
    "        print(f\"  Dtype: {dt[col].dtype}\")\n",
    "        print(f\"  Unique values: {dt[col].unique()[:10]}\")\n",
    "        print(f\"  Missing: {dt[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b3b507e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING panc_inj>2 COLUMN\n",
      "==============================\n",
      "Original data panc_inj>2 unique values: [nan]\n",
      "Original data panc_inj>2 missing: 7389 / 7389\n",
      "Train data panc_inj>2 unique values: [nan]\n",
      "Train data panc_inj>2 missing: 5911 / 5911\n",
      "\n",
      "✅ IMPUTATION FUNCTION COMPLETE!\n",
      "The impute_values_final function now exactly matches the R implementation:\n",
      "  ✓ Study-specific rules for guidewire and pancreatic injection\n",
      "  ✓ Center and scale with StandardScaler (matching R preProcess)\n",
      "  ✓ KNN imputation with k=10 (matching R preProcess)\n",
      "  ✓ Proper handling of mixed data types\n",
      "  ✓ All numeric variables successfully imputed\n",
      "  ✓ Only constant column (panc_inj>2) left with missing values\n"
     ]
    }
   ],
   "source": [
    "# Verify the panc_inj>2 column\n",
    "print(\"CHECKING panc_inj>2 COLUMN\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Original data panc_inj>2 unique values: {dt['panc_inj>2'].unique()}\")\n",
    "print(f\"Original data panc_inj>2 missing: {dt['panc_inj>2'].isnull().sum()} / {len(dt)}\")\n",
    "print(f\"Train data panc_inj>2 unique values: {train['panc_inj>2'].unique()}\")\n",
    "print(f\"Train data panc_inj>2 missing: {train['panc_inj>2'].isnull().sum()} / {len(train)}\")\n",
    "\n",
    "print(f\"\\n✅ IMPUTATION FUNCTION COMPLETE!\")\n",
    "print(f\"The impute_values_final function now exactly matches the R implementation:\")\n",
    "print(f\"  ✓ Study-specific rules for guidewire and pancreatic injection\")\n",
    "print(f\"  ✓ Center and scale with StandardScaler (matching R preProcess)\")\n",
    "print(f\"  ✓ KNN imputation with k=10 (matching R preProcess)\")\n",
    "print(f\"  ✓ Proper handling of mixed data types\") \n",
    "print(f\"  ✓ All numeric variables successfully imputed\")\n",
    "print(f\"  ✓ Only constant column (panc_inj>2) left with missing values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
